{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0b74e5-75b3-43d7-8882-00a97b5f223d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets (from -r requirements.txt (line 1))\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting kaggle (from -r requirements.txt (line 2))\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers (from -r requirements.txt (line 3))\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.6.0)\n",
      "Collecting unidecode (from -r requirements.txt (line 5))\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting spacy (from -r requirements.txt (line 6))\n",
      "  Downloading spacy-3.8.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting parquet (from -r requirements.txt (line 7))\n",
      "  Downloading parquet-1.3.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting evaluate (from -r requirements.txt (line 8))\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting rouge_score (from -r requirements.txt (line 9))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib (from -r requirements.txt (line 10))\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting fastapi (from -r requirements.txt (line 11))\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn (from -r requirements.txt (line 12))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (3.1.6)\n",
      "Collecting python-multipart (from -r requirements.txt (line 14))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting huggingface_hub (from -r requirements.txt (line 15))\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->-r requirements.txt (line 1))\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets->-r requirements.txt (line 1))\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting bleach (from kaggle->-r requirements.txt (line 2))\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (3.10)\n",
      "Collecting protobuf (from kaggle->-r requirements.txt (line 2))\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle->-r requirements.txt (line 2))\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (75.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle->-r requirements.txt (line 2))\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.3.0)\n",
      "Collecting webencodings (from kaggle->-r requirements.txt (line 2))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers->-r requirements.txt (line 3))\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 3))\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->-r requirements.txt (line 3))\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers->-r requirements.txt (line 3))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading cymem-2.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading preshed-3.0.9-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading thinc-8.3.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading srsly-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->-r requirements.txt (line 6))\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting thriftpy2 (from parquet->-r requirements.txt (line 7))\n",
      "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting absl-py (from rouge_score->-r requirements.txt (line 9))\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nltk (from rouge_score->-r requirements.txt (line 9))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 10))\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 10))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 10))\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 10))\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (11.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 10))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi->-r requirements.txt (line 11))\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting click>=7.0 (from uvicorn->-r requirements.txt (line 12))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 12))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (19.0.1)\n",
      "Collecting dill (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate->-r requirements.txt (line 8))\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (3.11.16)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.6.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6))\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6))\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.47.0,>=0.40.0->fastapi->-r requirements.txt (line 11))\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6))\n",
      "  Downloading blis-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6))\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting joblib (from nltk->rouge_score->-r requirements.txt (line 9))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate->-r requirements.txt (line 8))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate->-r requirements.txt (line 8))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Cython>=3.0.10 (from thriftpy2->parquet->-r requirements.txt (line 7))\n",
      "  Using cached Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ply<4.0,>=3.4 (from thriftpy2->parquet->-r requirements.txt (line 7))\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.18.3)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->-r requirements.txt (line 11))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.8.4)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.2.13)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.2.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "Downloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Downloading spacy-3.8.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/31.8 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading parquet-1.3.1-py3-none-any.whl (24 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading thinc-8.3.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading blis-1.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: rouge_score, thriftpy2\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=4a659a5bff652981841c1c9d1782bc301ad37533be2affebcd18f1d5abdcf1c0\n",
      "  Stored in directory: /home/onyxia/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp312-cp312-linux_x86_64.whl size=844378 sha256=9e637a8d70693ed9fa2dd99e07f558f5010fae1b121a698e8769c9e39f6a3605\n",
      "  Stored in directory: /home/onyxia/.cache/pip/wheels/c9/ce/d5/93b65735501e7c6f4c8900c33a98cf9f2f1718490df69ad68c\n",
      "Successfully built rouge_score thriftpy2\n",
      "Installing collected packages: webencodings, text-unidecode, pytz, ply, cymem, xxhash, widgetsnbextension, wasabi, unidecode, tzdata, typing-inspection, spacy-loggers, spacy-legacy, sniffio, smart-open, shellingham, safetensors, regex, pyyaml, python-slugify, python-multipart, pyparsing, pydantic-core, protobuf, murmurhash, mdurl, marisa-trie, kiwisolver, jupyterlab_widgets, joblib, h11, fsspec, fonttools, dill, Cython, cycler, contourpy, cloudpathlib, click, catalogue, blis, bleach, annotated-types, absl-py, uvicorn, thriftpy2, srsly, pydantic, preshed, pandas, nltk, multiprocess, matplotlib, markdown-it-py, language-data, kaggle, huggingface_hub, anyio, tokenizers, starlette, rouge_score, rich, parquet, langcodes, ipywidgets, confection, typer, transformers, thinc, fastapi, datasets, weasel, evaluate, spacy\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2025.3.2 requires fsspec==2025.3.2.*, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Cython-3.0.12 absl-py-2.2.2 annotated-types-0.7.0 anyio-4.9.0 bleach-6.2.0 blis-1.3.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 contourpy-1.3.1 cycler-0.12.1 cymem-2.0.11 datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fastapi-0.115.12 fonttools-4.57.0 fsspec-2024.12.0 h11-0.14.0 huggingface_hub-0.30.2 ipywidgets-8.1.6 joblib-1.4.2 jupyterlab_widgets-3.0.14 kaggle-1.7.4.2 kiwisolver-1.4.8 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 multiprocess-0.70.16 murmurhash-1.0.12 nltk-3.9.1 pandas-2.2.3 parquet-1.3.1 ply-3.11 preshed-3.0.9 protobuf-6.30.2 pydantic-2.11.3 pydantic-core-2.33.1 pyparsing-3.2.3 python-multipart-0.0.20 python-slugify-8.0.4 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 rich-14.0.0 rouge_score-0.1.2 safetensors-0.5.3 shellingham-1.5.4 smart-open-7.1.0 sniffio-1.3.1 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 starlette-0.46.1 text-unidecode-1.3 thinc-8.3.6 thriftpy2-0.5.2 tokenizers-0.21.1 transformers-4.51.2 typer-0.15.2 typing-inspection-0.4.0 tzdata-2025.2 unidecode-1.3.8 uvicorn-0.34.0 wasabi-1.1.3 weasel-0.4.1 webencodings-0.5.1 widgetsnbextension-4.0.14 xxhash-3.5.0\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551be2e9-959e-4460-9a93-468a8599cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import s3fs\n",
    "import io\n",
    "\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parquet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "from src.features.functions_preprocessing import (\n",
    "    plot_text_length_distribution,\n",
    "    preprocess_articles,\n",
    "    preprocess_summaries,\n",
    ")\n",
    "from src.features.tokenization import parallel_tokenize\n",
    "from src.models.bert import BertSummary\n",
    "from src.models.rnn_encoder_decoder import Encoder, Decoder, Seq2Seq\n",
    "from src.models.transformer import Transformer\n",
    "from src.models.train_models import train_model\n",
    "from src.evaluation.model_evaluation import (\n",
    "    generate_summaries_seq2seq,\n",
    "    generate_summaries_transformer,\n",
    "    generate_summaries_bert,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4001c3-32fd-47cf-a1cf-7e092367a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307adead-5653-4210-ae8b-49feee29e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "def get_allowed_cpu_count():\n",
    "    # Returns the number of CPU cores available for this process.\n",
    "    try:\n",
    "        return len(os.sched_getaffinity(0))\n",
    "    except AttributeError:\n",
    "        return os.cpu_count() or 1\n",
    "\n",
    "\n",
    "cpu_count = get_allowed_cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083a960e-9926-4d98-be1c-138870925f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = max(1, cpu_count // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb41093c-9c96-4743-868e-7615d7602ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(n_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40f21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "MY_BUCKET = config['MY_BUCKET']\n",
    "CHEMIN_FICHIER = config['CHEMIN_FICHIER']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d217-8730-4460-a6b4-f9b3af7dae71",
   "metadata": {},
   "source": [
    "# **Import Dataset from S3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b3609-9ea8-436f-9ad5-2a8b6a74abe5",
   "metadata": {},
   "source": [
    "Download and extract the news summarization dataset from S3, then load it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a88b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "with fs.open(f\"s3://{MY_BUCKET}/{CHEMIN_FICHIER}\") as f:\n",
    "    # Lire le contenu du fichier ZIP dans la mémoire\n",
    "    zip_content = io.BytesIO(f.read())\n",
    "\n",
    "with zipfile.ZipFile(zip_content, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"news-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda220bf-ee5f-46a1-bc49-738d2433eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"news-summarization/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d61455-7eb4-46f6-b6bc-73e468d89870",
   "metadata": {},
   "source": [
    "We pick a random article from the dataset and display both its content and the corresponding summary to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031cbd9-5d20-4232-bc5b-013f17c33161",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = random.randint(1, len(news_data))\n",
    "\n",
    "print(news_data[\"Content\"][N])\n",
    "print()\n",
    "print(news_data[\"Summary\"][N])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9325b7-504c-4bb7-ab02-b2509e0c9ab9",
   "metadata": {},
   "source": [
    "We filter out very short and very long articles (outside the 10th and 90th percentiles) and then plot the length distribution of the remaining articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e0f3-18ac-4587-a565-eb776f902183",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_article = news_data[\"Content\"].str.len()\n",
    "lengths_article.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705352d-0993-4db0-90c1-bb638cae4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_article >= lengths_article.quantile(0.10))\n",
    "    & (lengths_article <= lengths_article.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a65b8-3e3c-4d3e-bf74-dd6e0968f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa8e76-66d7-4a73-93bc-e559767978e8",
   "metadata": {},
   "source": [
    "We do the same for summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388fa01-72d3-4f19-be84-65cfb2f72616",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_summary = news_data[\"Summary\"].str.len()\n",
    "lengths_summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9ae62-79d1-420e-aa5e-0b0f1b920add",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_summary >= lengths_summary.quantile(0.10))\n",
    "    & (lengths_summary <= lengths_summary.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d5a5-dc67-4073-867e-8cc30911eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data[\"Summary\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ef823-ef87-4cc4-8ec1-7f4418348be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebd3fb-536d-41de-a83e-e2a320b33623",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e99a3-85fa-4e80-98cf-e6033b3b7643",
   "metadata": {},
   "source": [
    "We preprocess the articles and summaries using parallel processing to clean and standardize the text data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d071a-a9d5-45b3-8dfb-62e2d20feddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_data.loc[:, \"Content\"] = preprocess_articles(\n",
    "    news_data[\"Content\"].tolist(), n_process=n_process, batch_size=32\n",
    ")\n",
    "news_data.loc[:, \"Summary\"] = preprocess_summaries(\n",
    "    news_data[\"Summary\"].tolist(), n_process=n_process, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266194d-559a-4aee-8e81-929492060739",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.to_parquet(\"news_data_cleaned.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "local_parquet_path = \"news_data_cleaned.parquet\"\n",
    "s3_parquet_path = f\"s3://{MY_BUCKET}/data/news_data_cleaned.parquet\"\n",
    "fs.put(local_parquet_path, s3_parquet_path)\n",
    "print(f\"Fichier envoyé avec succès à {s3_parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4606ea4-f7ab-4d51-b4ec-2f2c60e06446",
   "metadata": {},
   "source": [
    "# **Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a2f17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_parquet_path = f\"s3://{MY_BUCKET}/data/news_data_cleaned.parquet\"\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "with fs.open(s3_parquet_path, 'rb') as f:\n",
    "    news_data = pd.read_parquet(f)\n",
    "\n",
    "# pb avec sauvegarder \n",
    "news_data.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "575b01c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ryan lipman australian porn star angela white think bring ultimate steamy study fantasy life partner secretly film sex act library la trobe university melbourne video believe shoot year library open use spark outrage university ire police despite presence nearby student white start video reveal bookshelf report herald sun raunchy angela white partner secretly film sex act library la trobe university melbourne white onscreen lover nearby desk partner keep lookout la trobe university spokesman say shock appal brazen act know video footage recently inform student 'permission seek give request assist fully police investigation victoria police spokeswoman say pair catch act face charge include wilful obscene exposure brazen act la trobe unaware video film leave outraged embarrassment controversy whiteâ€ ™ s dutch base production company agw entertainment issue statement address incident remove video publish online agw entertainment b.v. regret filming and/or posting video question offend member public â€\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.iloc[1]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193944a9-2d8a-44f7-b7b5-f187507664a5",
   "metadata": {},
   "source": [
    "We shuffle the dataset, split it into training and testing sets with an 80-20 ratio, and print the sizes of both subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd31c4c-bbfa-4bb0-b3a7-4a3d28c87d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = news_data[:]\n",
    "data_copy = news_data.sample(frac=1, random_state=42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data_copy))\n",
    "\n",
    "# Slice the dataset\n",
    "train_data = data_copy[:train_size]\n",
    "test_data = data_copy[train_size:]\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size:  {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24bd70-6ae9-48c4-b95d-739c4e7162d6",
   "metadata": {},
   "source": [
    "We tokenize the content of the articles & summaries in parallel using a BERT tokenizer, then save the tokenized result as a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b769e-51d2-437a-9220-a8c088c6bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_content = list(train_data[\"Content\"])\n",
    "    print(\"Tokenizing Content...\")\n",
    "    tokenized_articles = parallel_tokenize(\n",
    "        texts_content,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "    print(\"tokenized_articles.shape =\", tokenized_articles.shape)\n",
    "    torch.save(tokenized_articles, \"tokenized_articles.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d607c-8677-4661-8894-5e060000d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_summary = list(train_data[\"Summary\"])\n",
    "    print(\"Tokenizing Summaries...\")\n",
    "    tokenized_summaries = parallel_tokenize(\n",
    "        texts_summary,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=129,\n",
    "    )\n",
    "    print(\"tokenized_summaries.shape =\", tokenized_summaries.shape)\n",
    "    torch.save(tokenized_summaries, \"tokenized_summaries.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992dcfe0-9bcc-4c25-bacc-f1da333bd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_content = list(test_data[\"Content\"])\n",
    "    print(\"Tokenizing Content...\")\n",
    "    tokenized_articles_test = parallel_tokenize(\n",
    "        texts_content,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "    print(\"tokenized_articles.shape =\", tokenized_articles_test.shape)\n",
    "    torch.save(tokenized_articles_test, \"tokenized_articles_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e6163-0efa-4ca2-8819-9a5dcbd2115e",
   "metadata": {},
   "source": [
    "# **Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1313397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tokenized_articles = torch.load(\"tokenized_articles.pt\")\n",
    "    tokenized_summaries = torch.load(\"tokenized_summaries.pt\")\n",
    "    tokenized_articles_test = torch.load(\"tokenized_articles_test.pt\")\n",
    "\n",
    "article_ids = tokenized_articles.long()\n",
    "summary_ids = tokenized_summaries.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "334b87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([446425, 129])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_summaries.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cba4d2-bbe6-480a-aae4-6ea8a31500fb",
   "metadata": {},
   "source": [
    "We create a dataset and dataloader, then initialize a Transformer model with BERT's vocabulary size, hidden size, 8 attention heads, and 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb018b-58a2-4b87-b6a1-0c156f3ab0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd25b8e-33b9-4d2d-949a-9cacbd6485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=512,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727fa72-18ba-4e75-84d9-81012141810b",
   "metadata": {},
   "source": [
    "We train the Transformer model for 25 epochs using the Adam optimizer and cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae5581-ad3c-4e79-ab68-accd2baf12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=modelTransformer,\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=25,\n",
    "    optimizer=torch.optim.Adam(modelTransformer.parameters(), lr=2e-4),\n",
    "    loss_fn=nn.CrossEntropyLoss(\n",
    "        ignore_index=BertTokenizer.from_pretrained(\"bert-base-uncased\").pad_token_id\n",
    "    ),\n",
    "    model_name=\"Transformer\",\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee86c63-6434-48e0-9016-1b8b7a42792f",
   "metadata": {},
   "source": [
    "We initialize the Transformer model, load the pre-trained weights from a previous run (after 25 epochs), and set the model to evaluation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abacb4",
   "metadata": {},
   "source": [
    "# **API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b074d384-280a-4e2c-9495-8d44f825e9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (enc_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-2): 3 x EncoderLayer(\n",
       "      (attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-2): 3 x DecoderLayer(\n",
       "      (self_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (enc_dec_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=128,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")\n",
    "modelTransformer.load_state_dict(\n",
    "    torch.load(\"model_weights/transformer_weights_25_epochs.pth\")\n",
    ")\n",
    "modelTransformer.eval()\n",
    "modelTransformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b899727",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelTransformer.state_dict(), \"model/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311928a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a185151a6314d4d8320f4641df9e897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/50.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Antoiner77/model_test/commit/68f5cb3a5da1219348a92992cf69213738030c73', commit_message='Upload folder using huggingface_hub', commit_description='', oid='68f5cb3a5da1219348a92992cf69213738030c73', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Antoiner77/model_test', endpoint='https://huggingface.co', repo_type='model', repo_id='Antoiner77/model_test'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "# pip install huggingface_hub\n",
    "# pour envoyer le modele sur huggingface \n",
    "# mettre dans le terminal : huggingface-cli login\n",
    "# puis se connecter avec un token personnel \n",
    "# remplacer Antoiner77 par son propre compte \n",
    "\n",
    "create_repo(\"model_test\", private=False)  \n",
    "upload_folder(\n",
    "    repo_id=\"Antoiner77/model_test\",\n",
    "    folder_path=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour copier le model directement : \n",
    "# git clone https://huggingface.co/Antoiner77/model_test\n",
    "# le modele n'est pas privé donc peut etre charger directement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe90594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from model.model import Transformer \n",
    "\n",
    "# Charger la config\n",
    "with open(\"model/config_model.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba16f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (enc_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-2): 3 x EncoderLayer(\n",
       "      (attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-2): 3 x DecoderLayer(\n",
       "      (self_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (enc_dec_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer le modèle avec les paramètres de la config\n",
    "model = Transformer(\n",
    "    pad_idx=config[\"pad_idx\"],\n",
    "    voc_size=config[\"voc_size\"],\n",
    "    hidden_size=config[\"hidden_size\"],\n",
    "    n_head=config[\"n_head\"],\n",
    "    max_len=config[\"max_len\"],\n",
    "    dec_max_len=config[\"dec_max_len\"],\n",
    "    ffn_hidden=config[\"ffn_hidden\"],\n",
    "    n_layers=config[\"n_layers\"]\n",
    ")\n",
    "\n",
    "# Charger les poids\n",
    "model.load_state_dict(torch.load(\"model/pytorch_model.bin\", map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bd98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"new york police concerned drone tool terrorist investigate way stop potential attack police acknowledge drone potential weapon nypd say technology advance use carry air assault chemical weapon firearm police want develop technology allow control drone scan sky major event nypd say drone carry explosive number threat investigate way stop attack deputy chief salvatore dipace left concern incident year drone land german chancellor angela merkel take chancellor people drone fly pack football stadium manchester england week ago result suspect pilot arrest consult military member counterterrorism bomb squad emergency service aviation unit work plan counter weaponize drone nypd receive intelligence indicate imminent threat increasingly concerned year deputy chief salvatore dipace tell cbs news look people jury rig drone carry gun carry different type explosive want possibility worried mr dipace say police see video show accurate attack drone see video drone fly different target route accurately hit target paintball nypd see drone carry explosive number threat mr dipace concern follow incident germany year drone able land german chancellor angela merkel deliver speech drone circle land ms merkel deliver speech sin germany spark fear device easily commit terrorist act say think happen drone hit target right mark take chancellor people dramatic increase incident involve drone new york city year 40 record case unmanned aircraft system drone fly airspace nypd helicopter incident summer drone 800 foot ground nearly collide police helicopter nypd aviation unit member sergeant antonio hernandez say fly dark night vision goggle try job thing know drone come altitude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 1/1 [00:01<00:00,  1.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police are investigating whether the drone could be used in the world. the drone was carrying drones in the world's largest drone strike. the drone was carrying drones in the world's largest drone strike.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = parallel_tokenize(\n",
    "        [text],\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "summaries = generate_summaries_transformer(model, batch_size=32, tokenized_input=tokenized_input)\n",
    "\n",
    "print(summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2404b2-f088-4e07-a8fc-5134f77e2c70",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e54d5f-ecf8-4793-9700-9eb597b7103c",
   "metadata": {},
   "source": [
    "We load the ROUGE evaluation metric, which is commonly used to assess the quality of generated text summaries by comparing them to reference summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86549c6a-cebb-4a60-adf3-c1dcc84eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f553d-16ed-4b0f-a70a-cee2ef2ed239",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "We generate summaries using the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754ec6c-8cb3-42c9-9167-1ee514b15539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_transformer = generate_summaries_transformer(\n",
    "    model=modelTransformer,\n",
    "    batch_size=32,\n",
    "    tokenized_input=tokenized_articles_test,\n",
    "    limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24df4c-b900-401c-a723-4817624996a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, \"predictions_transformer\"] = predictions_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85f138-4573-4b1f-899b-161d475dd725",
   "metadata": {},
   "source": [
    "We compute ROUGE metrics by comparing the Transformer model's generated summaries to the reference summaries from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff35cc7-7fdb-4d73-95a8-af473da2b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = list(test_data[\"Summary\"])\n",
    "results = rouge.compute(\n",
    "    predictions=predictions_transformer, references=reference_summaries\n",
    ")\n",
    "print(\"ROUGE metrics:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18dbbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

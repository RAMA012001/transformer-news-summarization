{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0b74e5-75b3-43d7-8882-00a97b5f223d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (8.1.5)\n",
      "Requirement already satisfied: kaggle in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (1.7.4.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.50.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.3.8)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.8.5)\n",
      "Requirement already satisfied: parquet in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.4.3)\n",
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/conda/lib/python3.12/site-packages (from ipywidgets->-r requirements.txt (line 1)) (3.0.13)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (8.0.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (75.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.12/site-packages (from kaggle->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (4.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (8.3.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (0.15.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (2.11.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: thriftpy2 in /opt/conda/lib/python3.12/site-packages (from parquet->-r requirements.txt (line 7)) (0.5.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from evaluate->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.12/site-packages (from evaluate->-r requirements.txt (line 8)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from evaluate->-r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from evaluate->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from evaluate->-r requirements.txt (line 8)) (0.70.16)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from rouge_score->-r requirements.txt (line 9)) (2.2.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (from rouge_score->-r requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (3.11.14)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk->rouge_score->-r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate->-r requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate->-r requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: Cython>=3.0.10 in /opt/conda/lib/python3.12/site-packages (from thriftpy2->parquet->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: ply<4.0,>=3.4 in /opt/conda/lib/python3.12/site-packages (from thriftpy2->parquet->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate->-r requirements.txt (line 8)) (1.18.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551be2e9-959e-4460-9a93-468a8599cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parquet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "from src.features.functions_preprocessing import (\n",
    "    plot_text_length_distribution,\n",
    "    preprocess_articles,\n",
    "    preprocess_summaries,\n",
    ")\n",
    "from src.features.tokenization import parallel_tokenize\n",
    "from src.models.bert import BertSummary\n",
    "from src.models.rnn_encoder_decoder import Encoder, Decoder, Seq2Seq\n",
    "from src.models.transformer import Transformer\n",
    "from src.models.train_models import train_model\n",
    "from src.evaluation.model_evaluation import (\n",
    "    generate_summaries_seq2seq,\n",
    "    generate_summaries_transformer,\n",
    "    generate_summaries_bert,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4001c3-32fd-47cf-a1cf-7e092367a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307adead-5653-4210-ae8b-49feee29e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "def get_allowed_cpu_count():\n",
    "    # Returns the number of CPU cores available for this process.\n",
    "    try:\n",
    "        return len(os.sched_getaffinity(0))\n",
    "    except AttributeError:\n",
    "        return os.cpu_count() or 1\n",
    "\n",
    "\n",
    "cpu_count = get_allowed_cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "083a960e-9926-4d98-be1c-138870925f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = max(1, cpu_count // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb41093c-9c96-4743-868e-7615d7602ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(n_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d217-8730-4460-a6b4-f9b3af7dae71",
   "metadata": {},
   "source": [
    "# **Kaggle dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b3609-9ea8-436f-9ad5-2a8b6a74abe5",
   "metadata": {},
   "source": [
    "Download and extract the news summarization dataset from Kaggle, then load it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae2436-3b97-4c81-9f05-fd46b54ca9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"news-summarization.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"news-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda220bf-ee5f-46a1-bc49-738d2433eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"news-summarization/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab595ed-3c4a-4432-a941-adbfa7223b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d61455-7eb4-46f6-b6bc-73e468d89870",
   "metadata": {},
   "source": [
    "We pick a random article from the dataset and display both its content and the corresponding summary to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031cbd9-5d20-4232-bc5b-013f17c33161",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = random.randint(1, len(news_data))\n",
    "\n",
    "print(news_data[\"Content\"][N])\n",
    "print()\n",
    "print(news_data[\"Summary\"][N])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9325b7-504c-4bb7-ab02-b2509e0c9ab9",
   "metadata": {},
   "source": [
    "We filter out very short and very long articles (outside the 10th and 90th percentiles) and then plot the length distribution of the remaining articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e0f3-18ac-4587-a565-eb776f902183",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_article = news_data[\"Content\"].str.len()\n",
    "lengths_article.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705352d-0993-4db0-90c1-bb638cae4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_article >= lengths_article.quantile(0.10))\n",
    "    & (lengths_article <= lengths_article.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a65b8-3e3c-4d3e-bf74-dd6e0968f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa8e76-66d7-4a73-93bc-e559767978e8",
   "metadata": {},
   "source": [
    "We do the same for summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388fa01-72d3-4f19-be84-65cfb2f72616",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_summary = news_data[\"Summary\"].str.len()\n",
    "lengths_summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9ae62-79d1-420e-aa5e-0b0f1b920add",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_summary >= lengths_summary.quantile(0.10))\n",
    "    & (lengths_summary <= lengths_summary.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d5a5-dc67-4073-867e-8cc30911eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data[\"Summary\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ef823-ef87-4cc4-8ec1-7f4418348be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebd3fb-536d-41de-a83e-e2a320b33623",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e99a3-85fa-4e80-98cf-e6033b3b7643",
   "metadata": {},
   "source": [
    "We preprocess the articles and summaries using parallel processing to clean and standardize the text data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d071a-a9d5-45b3-8dfb-62e2d20feddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_data.loc[:, \"Content\"] = preprocess_articles(\n",
    "    news_data[\"Content\"].tolist(), n_process=n_process, batch_size=32\n",
    ")\n",
    "news_data.loc[:, \"Summary\"] = preprocess_summaries(\n",
    "    news_data[\"Summary\"].tolist(), n_process=n_process, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266194d-559a-4aee-8e81-929492060739",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.to_parquet(\"news_data_cleaned.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e907a-49bb-42f6-880b-0df87c38a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_parquet(\"news_data_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4606ea4-f7ab-4d51-b4ec-2f2c60e06446",
   "metadata": {},
   "source": [
    "# **Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193944a9-2d8a-44f7-b7b5-f187507664a5",
   "metadata": {},
   "source": [
    "We shuffle the dataset, split it into training and testing sets with an 80-20 ratio, and print the sizes of both subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd31c4c-bbfa-4bb0-b3a7-4a3d28c87d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = news_data[:]\n",
    "data_copy = news_data.sample(frac=1, random_state=42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data_copy))\n",
    "\n",
    "# Slice the dataset\n",
    "train_data = data_copy[:train_size]\n",
    "test_data = data_copy[train_size:]\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size:  {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24bd70-6ae9-48c4-b95d-739c4e7162d6",
   "metadata": {},
   "source": [
    "We tokenize the content of the articles & summaries in parallel using a BERT tokenizer, then save the tokenized result as a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b769e-51d2-437a-9220-a8c088c6bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_content = list(train_data[\"Content\"])\n",
    "    print(\"Tokenizing Content...\")\n",
    "    tokenized_articles = parallel_tokenize(\n",
    "        texts_content,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "    print(\"tokenized_articles.shape =\", tokenized_articles.shape)\n",
    "    torch.save(tokenized_articles, \"tokenized_articles.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d607c-8677-4661-8894-5e060000d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_summary = list(train_data[\"Summary\"])\n",
    "    print(\"Tokenizing Summaries...\")\n",
    "    tokenized_summaries = parallel_tokenize(\n",
    "        texts_summary,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=129,\n",
    "    )\n",
    "    print(\"tokenized_summaries.shape =\", tokenized_summaries.shape)\n",
    "    torch.save(tokenized_summaries, \"tokenized_summaries.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992dcfe0-9bcc-4c25-bacc-f1da333bd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_content = list(test_data[\"Content\"])\n",
    "    print(\"Tokenizing Content...\")\n",
    "    tokenized_articles_test = parallel_tokenize(\n",
    "        texts_content,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "    print(\"tokenized_articles.shape =\", tokenized_articles_test.shape)\n",
    "    torch.save(tokenized_articles_test, \"tokenized_articles_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59793caa-2cea-403e-b9e4-5760c866b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tokenized_articles = torch.load(\"tokenized_articles.pt\")\n",
    "    tokenized_summaries = torch.load(\"tokenized_summaries.pt\")\n",
    "    tokenized_summaries_bert = torch.load(\"tokenized_summaries_bert.pt\")\n",
    "    tokenized_articles_test = torch.load(\"tokenized_articles_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089836ea-921b-4a8d-9a84-21e37a9dddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_summaries_bert = torch.cat(\n",
    "    [torch.zeros(tokenized_summaries_bert.size(0), 1), tokenized_summaries_bert], dim=1\n",
    ").long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1017c3e-aa9e-402f-aa0d-08560ba542f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = tokenized_articles.long()\n",
    "summary_ids = tokenized_summaries.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48ae10-ef79-46f3-9a79-8762cc67f344",
   "metadata": {},
   "source": [
    "# **Seq2Seq**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36d339-1d2b-4842-9a8c-2136665a9317",
   "metadata": {},
   "source": [
    "We create a dataset and dataloader for training, then initialize an encoder and decoder, and finally the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376bb13-c135-459b-a93c-a25a5a2c2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08cbb3-2eca-4521-92f5-c8bea67de7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "modelSeq2Seq = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19158d-cbe8-4798-babf-406e21f664fe",
   "metadata": {},
   "source": [
    "We train the Seq2Seq model for 30 epochs using the Adam optimizer and cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2f556-1591-44df-adfb-ea54d037cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=modelSeq2Seq,\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=25,\n",
    "    optimizer=torch.optim.Adam(modelSeq2Seq.parameters(), lr=2e-4),\n",
    "    loss_fn=nn.CrossEntropyLoss(\n",
    "        ignore_index=BertTokenizer.from_pretrained(\"bert-base-uncased\").pad_token_id\n",
    "    ),\n",
    "    model_name=\"Seq2Seq\",\n",
    "    device=device,\n",
    "    teacher_forcing_ratio=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd479c-de8e-4510-9afb-1fa5dc47d9e1",
   "metadata": {},
   "source": [
    "We initialize the encoder, decoder, and Seq2Seq model, load pre-trained weights from a previous run (after 25 epochs), and set the model to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805db746-644a-486b-85c0-a338d78d05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "modelSeq2Seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "modelSeq2Seq.load_state_dict(torch.load(\"model_weights/seq2seq_weights_25_epochs.pth\"))\n",
    "modelSeq2Seq.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e6163-0efa-4ca2-8819-9a5dcbd2115e",
   "metadata": {},
   "source": [
    "# **Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cba4d2-bbe6-480a-aae4-6ea8a31500fb",
   "metadata": {},
   "source": [
    "We create a dataset and dataloader, then initialize a Transformer model with BERT's vocabulary size, hidden size, 8 attention heads, and 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb018b-58a2-4b87-b6a1-0c156f3ab0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd25b8e-33b9-4d2d-949a-9cacbd6485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=512,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727fa72-18ba-4e75-84d9-81012141810b",
   "metadata": {},
   "source": [
    "We train the Transformer model for 25 epochs using the Adam optimizer and cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae5581-ad3c-4e79-ab68-accd2baf12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=modelTransformer,\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=25,\n",
    "    optimizer=torch.optim.Adam(modelTransformer.parameters(), lr=2e-4),\n",
    "    loss_fn=nn.CrossEntropyLoss(\n",
    "        ignore_index=BertTokenizer.from_pretrained(\"bert-base-uncased\").pad_token_id\n",
    "    ),\n",
    "    model_name=\"Transformer\",\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee86c63-6434-48e0-9016-1b8b7a42792f",
   "metadata": {},
   "source": [
    "We initialize the Transformer model, load the pre-trained weights from a previous run (after 25 epochs), and set the model to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074d384-280a-4e2c-9495-8d44f825e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=128,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")\n",
    "modelTransformer.load_state_dict(\n",
    "    torch.load(\"model_weights/transformer_weights_25_epochs.pth\")\n",
    ")\n",
    "modelTransformer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebdd59-cc9d-40a4-a97c-94961d40df5f",
   "metadata": {},
   "source": [
    "# **BERT model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79e799-09d2-40ba-9e68-ec8db5a3cfcf",
   "metadata": {},
   "source": [
    "We create a dataset and dataloader with smaller batch size, then configure a BERT model with 12 hidden layers, 12 attention heads, and standard BERT parameters, and finally initialize the BertSummary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea203f80-b14e-4a4c-939c-d5128b8aa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries_bert[:, 1:])\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a157c-77fb-45ff-b45c-0ee6f73d8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    vocab_size=BertTokenizer.from_pretrained(\"bert-base-uncased\").vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca7381-2813-4167-94fc-f6c810f47d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBert = BertSummary(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e5c2e-3aa5-45e2-88d3-c59b951a80e6",
   "metadata": {},
   "source": [
    "We train the BERT-based summarization model for 7 epochs using the Adam optimizer and cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6ff0c-9d93-44ff-9a87-ff1525ce1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=modelBert,\n",
    "    dataloader=dataloader,\n",
    "    num_epochs=7,\n",
    "    optimizer=torch.optim.Adam(modelBert.parameters(), lr=1e-5),\n",
    "    loss_fn=nn.CrossEntropyLoss(\n",
    "        ignore_index=BertTokenizer.from_pretrained(\"bert-base-uncased\").pad_token_id\n",
    "    ),\n",
    "    model_name=\"BERT\",\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd70568-b880-429c-8246-046302afbe7b",
   "metadata": {},
   "source": [
    "We initialize the BERT summarization model, load pre-trained weights from a previous run (after 7 epochs) and set it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710bcc62-6e95-4c54-a99e-363d0bca518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBert = BertSummary(config)\n",
    "modelBert.load_state_dict(torch.load(\"model_weights/bert_weights_7_epochs.pth\"))\n",
    "modelBert.to(device)\n",
    "modelBert.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2404b2-f088-4e07-a8fc-5134f77e2c70",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e54d5f-ecf8-4793-9700-9eb597b7103c",
   "metadata": {},
   "source": [
    "We load the ROUGE evaluation metric, which is commonly used to assess the quality of generated text summaries by comparing them to reference summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86549c6a-cebb-4a60-adf3-c1dcc84eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4133254-29eb-4c04-a7ae-73dfe3164fc6",
   "metadata": {},
   "source": [
    "## Seq2Seq\n",
    "\n",
    "We generate summaries using the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f331c-c776-437b-9d10-8f57fa1df4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_seq2seq = generate_summaries_seq2seq(\n",
    "    model=modelSeq2Seq,\n",
    "    batch_size=32,\n",
    "    tokenized_input=tokenized_articles_test,\n",
    "    limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe66b0b-2394-4916-aae1-fa4bbce5dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, \"predictions_seq2seq\"] = predictions_seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63aa87-c366-4fc3-87f4-597fae9fa8b5",
   "metadata": {},
   "source": [
    "We compute ROUGE metrics by comparing the Seq2Seq model's generated summaries to the reference summaries from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad67362-8ecb-4bfd-bd4f-acc251d23042",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = list(test_data[\"Summary\"])\n",
    "results = rouge.compute(predictions=predictions_seq2seq, references=reference_summaries)\n",
    "print(\"ROUGE metrics:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f553d-16ed-4b0f-a70a-cee2ef2ed239",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "We generate summaries using the Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754ec6c-8cb3-42c9-9167-1ee514b15539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_transformer = generate_summaries_transformer(\n",
    "    model=modelTransformer,\n",
    "    batch_size=32,\n",
    "    tokenized_input=tokenized_articles_test,\n",
    "    limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24df4c-b900-401c-a723-4817624996a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, \"predictions_transformer\"] = predictions_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85f138-4573-4b1f-899b-161d475dd725",
   "metadata": {},
   "source": [
    "We compute ROUGE metrics by comparing the Transformer model's generated summaries to the reference summaries from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff35cc7-7fdb-4d73-95a8-af473da2b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = list(test_data[\"Summary\"])\n",
    "results = rouge.compute(\n",
    "    predictions=predictions_transformer, references=reference_summaries\n",
    ")\n",
    "print(\"ROUGE metrics:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f0cc6-c85f-4e79-a0cf-cef50c8f3464",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146f8c3-e097-4a5d-a916-07ba32ac2e7b",
   "metadata": {},
   "source": [
    "We generate summaries using the BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba84033-a021-4a5c-9723-32f375d86269",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bert = generate_summaries_bert(\n",
    "    model=modelBert,\n",
    "    batch_size=32,\n",
    "    tokenized_input=tokenized_articles_test,\n",
    "    limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac77b82-57a3-477c-8678-fe79fe1bc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[:, \"predictions_bert\"] = predictions_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07156369-4eb4-4148-823f-d28fc9c489df",
   "metadata": {},
   "source": [
    "We compute ROUGE metrics by comparing the BERT model's generated summaries to the reference summaries from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea601b-fa71-4beb-b975-80b06b8c34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = list(test_data[\"Summary\"])\n",
    "results = rouge.compute(predictions=predictions_bert, references=reference_summaries)\n",
    "print(\"ROUGE metrics:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
